{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "############################ Parameters  ####################################################\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "validation_split = 0.2\n",
    "optimizer = 'adam'\n",
    "loss = 'categorical_crossentropy'\n",
    "metrics = 'accuracy'\n",
    "#############################################################################################\n",
    "\n",
    "# Display parameters in a table\n",
    "param_table_data = [\n",
    "    (\"Epochs\", epochs),\n",
    "    (\"Batch Size\", batch_size),\n",
    "    (\"Validation Split\", validation_split),\n",
    "    (\"Optimizer\", optimizer),\n",
    "    (\"Loss\", loss),\n",
    "    (\"Metrics\", metrics)\n",
    "]\n",
    "\n",
    "param_table_headers = [\"Parameter\", \"Value\"]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.table(cellText=param_table_data, colLabels=param_table_headers, cellLoc='center', loc='center', bbox=[0, 0, 1, 1])\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer, loss, metrics)\n",
    "\n",
    "# Model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train the model and capture history for plotting\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "history = model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=validation_split, callbacks=[reduce_lr])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = model.predict(test_images[:5])\n",
    "print('Predictions:', predictions.argmax(axis=1))\n",
    "print('True labels:', test_labels[:5].argmax(axis=1))\n",
    "\n",
    "# Plot confusion matrix\n",
    "test_predictions = model.predict(test_images)\n",
    "conf_matrix = confusion_matrix(test_labels.argmax(axis=1), test_predictions.argmax(axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=range(10))\n",
    "plt.figure(figsize=(8, 8))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Visualize some sample predictions\n",
    "sample_indices = np.random.choice(len(test_images), 5, replace=False)\n",
    "sample_images = test_images[sample_indices]\n",
    "sample_labels = test_labels[sample_indices]\n",
    "\n",
    "sample_predictions = model.predict(sample_images)\n",
    "sample_predictions_labels = sample_predictions.argmax(axis=1)\n",
    "sample_true_labels = sample_labels.argmax(axis=1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"Pred: {sample_predictions_labels[i]}\\nTrue: {sample_true_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# Plot learning rate\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['lr'])\n",
    "plt.title('Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('LR')\n",
    "\n",
    "# Visualize filters from the first convolutional layer\n",
    "layer_outputs = [layer.output for layer in model.layers[:3]]\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "# Select an image from the test set\n",
    "img = test_images[0]\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Get activations of the first convolutional layer\n",
    "activations = activation_model.predict(img)\n",
    "\n",
    "# Plot filters\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(32):\n",
    "    plt.subplot(4, 8, i + 1)\n",
    "    plt.imshow(activations[0][0, :, :, i], cmap='viridis')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Filters from the First Convolutional Layer')\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(history.history['accuracy'], history.history['val_accuracy'])\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Training Accuracy')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(history.history['loss'], bins=20, label='Training Loss')\n",
    "plt.hist(history.history['val_loss'], bins=20, label='Validation Loss', alpha=0.7)\n",
    "plt.title('Distribution of Training and Validation Loss')\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Bubble chart\n",
    "epochs_range = range(1, epochs + 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(epochs_range, history.history['accuracy'], s=np.array(history.history['lr']) * 5000, c='red', alpha=0.5, label='Accuracy')\n",
    "plt.title('Accuracy and Learning Rate Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Area chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.fill_between(epochs_range, history.history['accuracy'], history.history['val_accuracy'], color='skyblue', alpha=0.4, label='Accuracy Area')\n",
    "plt.title('Accuracy Over Epochs with Validation Range')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Spline chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs_range, history.history['loss'], label='Training Loss', marker='o')\n",
    "plt.plot(epochs_range, history.history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
