{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPooli  (None, 15, 15, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (None, 6, 6, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               262272    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 356810 (1.36 MB)\n",
      "Trainable params: 356810 (1.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 1.5307 - accuracy: 0.4444 - val_loss: 1.3840 - val_accuracy: 0.5104 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 1.1711 - accuracy: 0.5836 - val_loss: 1.0585 - val_accuracy: 0.6261 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 0.9982 - accuracy: 0.6489 - val_loss: 0.9517 - val_accuracy: 0.6677 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 25s 40ms/step - loss: 0.8745 - accuracy: 0.6949 - val_loss: 0.9274 - val_accuracy: 0.6806 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.7753 - accuracy: 0.7304 - val_loss: 0.9076 - val_accuracy: 0.6867 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.6918 - accuracy: 0.7580 - val_loss: 0.8844 - val_accuracy: 0.6904 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.6069 - accuracy: 0.7877 - val_loss: 0.8525 - val_accuracy: 0.7145 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.5351 - accuracy: 0.8120 - val_loss: 0.8518 - val_accuracy: 0.7216 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4660 - accuracy: 0.8381 - val_loss: 0.8778 - val_accuracy: 0.7234 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 23s 38ms/step - loss: 0.4027 - accuracy: 0.8584 - val_loss: 0.8842 - val_accuracy: 0.7204 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.3397 - accuracy: 0.8817 - val_loss: 1.0264 - val_accuracy: 0.7069 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.1788 - accuracy: 0.9443 - val_loss: 1.0150 - val_accuracy: 0.7357 - lr: 2.0000e-04\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1408 - accuracy: 0.9585 - val_loss: 1.0615 - val_accuracy: 0.7324 - lr: 2.0000e-04\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.1206 - accuracy: 0.9661 - val_loss: 1.1254 - val_accuracy: 0.7286 - lr: 2.0000e-04\n",
      "Epoch 15/20\n",
      "142/625 [=====>........................] - ETA: 16s - loss: 0.0874 - accuracy: 0.9814"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "############################ Parameters  ####################################################\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "validation_split = 0.2\n",
    "optimizer = 'adam'\n",
    "loss= 'categorical_crossentropy'\n",
    "metrics= 'accuracy'\n",
    "#############################################################################################\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "# Build the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer, loss, metrics)\n",
    "\n",
    "# Model architecture\n",
    "model.summary()\n",
    "\n",
    "# Train the model and capture history for plotting\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "history = model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=validation_split, callbacks=[reduce_lr])\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = model.predict(test_images[:5])\n",
    "print('Predictions:', predictions.argmax(axis=1))\n",
    "print('True labels:', test_labels[:5].argmax(axis=1))\n",
    "\n",
    "# Plot confusion matrix\n",
    "test_predictions = model.predict(test_images)\n",
    "conf_matrix = confusion_matrix(test_labels.argmax(axis=1), test_predictions.argmax(axis=1))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=range(10))\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Visualize some sample predictions\n",
    "sample_indices = np.random.choice(len(test_images), 5, replace=False)\n",
    "sample_images = test_images[sample_indices]\n",
    "sample_labels = test_labels[sample_indices]\n",
    "\n",
    "sample_predictions = model.predict(sample_images)\n",
    "sample_predictions_labels = sample_predictions.argmax(axis=1)\n",
    "sample_true_labels = sample_labels.argmax(axis=1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.title(f\"Pred: {sample_predictions_labels[i]}\\nTrue: {sample_true_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# Plot learning rate\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['lr'])\n",
    "plt.title('Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('LR')\n",
    "plt.show()\n",
    "\n",
    "# Visualize filters from the first convolutional layer\n",
    "layer_outputs = [layer.output for layer in model.layers[:3]]  # Get the outputs of the first three layers\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)  # Create a model that will return these outputs, given the model input\n",
    "\n",
    "# Select an image from the test set\n",
    "img = test_images[0]\n",
    "img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "# Get activations of the first convolutional layer\n",
    "activations = activation_model.predict(img)\n",
    "\n",
    "# Plot filters\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(32):  # Assuming 32 filters in the first convolutional layer\n",
    "    plt.subplot(4, 8, i + 1)\n",
    "    plt.imshow(activations[0][0, :, :, i], cmap='viridis')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Filters from the First Convolutional Layer')\n",
    "plt.show()\n",
    "\n",
    "# Plot information graphic\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Model architecture\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.text(0.5, 0.5, 'Model Architecture', fontsize=14, ha='center', va='center', color='white')\n",
    "plt.axis('off')\n",
    "\n",
    "# Training & Validation Accuracy\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Training & Validation Loss\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.subplot(2, 3, 4)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# Sample Predictions\n",
    "plt.subplot(2, 3, 5)\n",
    "for i in range(5):\n",
    "    plt.text(i * 0.2, 0.7, f\"Pred: {sample_predictions_labels[i]}\\nTrue: {sample_true_labels[i]}\", fontsize=10, ha='left', va='center')\n",
    "    plt.imshow(sample_images[i])\n",
    "    plt.axis('off')\n",
    "plt.title('Sample Predictions')\n",
    "\n",
    "# Learning Rate\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.plot(history.history['lr'])\n",
    "plt.title('Learning Rate Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('LR')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
